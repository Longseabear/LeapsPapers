
# Deep Adversarial Attention Alignment for Unsupervised Domain Adaptation: the Benefit of Target Expectation Maximization 

## Index

1.	[Abstract](#Abstract)
2. [Introduce](#Introduce)
3.	[Related Work](#RelatedWork)
4.	[Approach](#Approach)
5.	Experiments
6.	[비고]

---
## Abstract
---------

* 라벨링된 데이터가 없을 때 어떻게 Domain Adaptation을 진행하지?
  * Attention 기반의 모델이 효과가 있더라 ( 가정: Data의 distribution은 달라져도 Attention은 동일할 것이다 )
  * Cycle Gan으로 unlabeling된 데이터셋을 labeling하고 다시 트레이닝하자.
  * 트레이닝 할 때는 attention의 차이를 최소화 하도록 모델을 트레이닝하자.
  

[Index바로가기](#index)

---
## Introduce
---------

Zagoruyko: "야씨 모델의 성능은 attention이 결정하더라"

저자: "그러므로, convolutional layer의 attention이 domain shift에 invariant할 것이다 ㅎㅎ"

그러니까, Source data을 cycleGAN으로 target data를 제작하고, 어텐션을 이용해서 네트워크 트레이닝에 패널티를 부여하자.  
즉, Attention의 변화를 최소화하면서 target data를 만들어봐.

따라서 다음을 제안:  
* Deep attention aligment method
* EM Algorithm: unlabeled target data으로 네트워크를 트레이닝하기 위함

Contiribution:
* 우리 것이 최고다 (Office-31 dataset에서)

---
## RelatedWork
---------

* Unsupervised domain adaptation
* Attention of CNNs
* Unpaired image-to-image translation

---
## Approach
---------
* Cycle GAN을 통하여 추가적인 데이터 생성
 * 즉, (Source -> Target) / (Target -> Source)
 * 4가지 입력 pair을 얻을 수 있음 (real source, real target, synthethic source, synthetic target)

* 고대로 네트워크 입력으로
 * 가정, Domain Adaptation에서 source image와 target image의 Attention map은 동일할 것이다.
 * 따라서 Attention regulization 테크닉을 적용 (간단하게 Feature의 square을 normalization한 것을 Attention이라고 정의 한 후, L2 Norm)
 
* Loss는 Cross entropy 동일.
 
-------



